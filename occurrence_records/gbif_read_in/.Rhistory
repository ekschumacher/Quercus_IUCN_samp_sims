(38000/52)/37.5
((38000/52)/37.5)*1.24
(((38000/52)/37.5)*1.24)*4
library(hierfstat)
hierfstat
?hierfstat
setwd("C:\\Users\\eschumacher\\Documents")
nanodrop_values <- read.csv("nandrop_shz_17_60.csv")
setwd("C:\\Users\\eschumacher\\Documents")
setwd("C:/Users/eschumacher/Documents")
setwd("C:\\Users\\eschumacher\\Documents\\primer_ordering_ZAIN")
setwd("C:\\Users\\eschumacher\\Documents")
read.csv("nanodrop_shz_17_60.csv")
nanodrop_values <- read.csv("nanodrop_shz_17_60.csv")
##set my working directory to my documents folder
setwd("C:\\Users\\eschumacher\\Documents")
##
nanodrop_values <- read.csv("nanodrop_shz_17_60.csv")
?t.test
t.test(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, paired = TRUE)
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop)
##now we run the t-test
t.test(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, paired = TRUE)
##
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop)
##
pdf("badblank_nanodrop.pdf")
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop)
dev.off()
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, ylim = c(-10, 10))
##
pdf("badblank_nanodrop.pdf")
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, ylim = c(-10, 10),
names = c("Before New Blank", "After New Blank"))
##
pdf("badblank_nanodrop.pdf")
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, ylim = c(-10, 10),
names = c("Before New Blank", "After New Blank"))
dev.off()
##
pdf("badblank_nanodrop.pdf")
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, ylim = c(-10, 10),
names = c("Before New Blank", "After New Blank"), title = "260/230 ratio comparisons before and after new blank")
dev.off()
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, ylim = c(-10, 10),
names = c("Before New Blank", "After New Blank"), ylab = c("260/230 Ratios"),
main = c("260/230 ratios before and after new blank"))
##
pdf("badblank_nanodrop.pdf")
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, ylim = c(-10, 10),
names = c("Before New Blank", "After New Blank"), ylab = c("260/230 Ratios"),
main = c("260/230 ratios before and after new blank"))
dev.off()
##
pdf("badblank_nanodrop.pdf")
boxplot(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, ylim = c(-10, 10),
names = c("Before New Blank", "After New Blank"), ylab = c("260/230 Ratios"),
main = c("260/230 ratios before and after new blank"))
dev.off()
##set my working directory to my documents folder
setwd("C:\\Users\\eschumacher\\Documents")
##load in nanodrop values
nanodrop_values <- read.csv("nanodrop_shz_17_60.csv")
##non-parametrc
wilcox.test(nanodrop_values$Old.Nanodrop, nanodrop_values$New.Nanodrop, paired = TRUE, alternative = "two.sided")
sum(134
83.8
48.2
21.2)
sum(134, 83.8, 48.2, 21.2)
library(adegenet)
library(poppr)
library(hierfstat)
library(PopGenReport)
library(pegas)
?pair.ia
################################################################################
# A) Read in target taxa list
################################################################################
##set working directory
#setwd("C:\\Users\\eschumacher\\Documents\\GitHub\\butternut\\SDMs")
my_dir <- "C:\\Users\\eschumacher\\Documents\\GitHub\\Quercus_IUCN_samp_sims\\occurrence_records"
setwd(my_dir)
# list of target taxon names
taxon_names <- c("Quercus acerifolia","Quercus arkansana",
"Quercus austrina", "Quercus boyntonii",
"Quercus camenensis", "Quercus cedrosensis",
"Quercus engelmannii", "Quercus georgiana",
"Quercus graciliformis", "Quercus havardii",
"Quercus hinckleyii", "Quercus oglethorpensis",
"Quercus pacifica", "Quercus tomentella")
# list of target species names
species_names <- c("Quercus acerifolia","Quercus arkansana",
"Quercus austrina", "Quercus boyntonii",
"Quercus camenensis", "Quercus cedrosensis",
"Quercus engelmannii", "Quercus georgiana",
"Quercus graciliformis", "Quercus havardii",
"Quercus hinckleyii", "Quercus oglethorpensis",
"Quercus pacifica", "Quercus tomentella")
library(plyr)
library(tidyverse) #ggplot2,dplyr,tidyr,readr,purrr,tibble,stringr,forcats
library(spocc)
library(rgbif)
library(data.table)
library(BIEN)
library(ridigbio)
library(batchtools)
library(bit64)
library(sp)
# GBIF account user information
# if you don't have account yet, go to https://www.gbif.org then click
#   "Login" in top right corner, then click "Register"
# !!! FILL THIS IN WITH YOUR INFO:
user <- "ekschu"
pwd <- Quercus5%
email <- eschumacher@mortonarb.org
# get GBIF taxon keys for all taxa in target list
keys <- sapply(taxon_names,function(x) name_backbone(name=x)$speciesKey,
simplify = "array")
# GBIF account user information
# if you don't have account yet, go to https://www.gbif.org then click
#   "Login" in top right corner, then click "Register"
# !!! FILL THIS IN WITH YOUR INFO:
user <- "ekschu"
pwd <- "Quercus5%"
# GBIF account user information
# if you don't have account yet, go to https://www.gbif.org then click
#   "Login" in top right corner, then click "Register"
# !!! FILL THIS IN WITH YOUR INFO:
user <- "ekschu"
pwd <- "Quercus5%"
email <- "eschumacher@mortonarb.org"
# get GBIF taxon keys for all taxa in target list
keys <- sapply(taxon_names,function(x) name_backbone(name=x)$speciesKey,
simplify = "array")
# remove duplicate and NULL keys
keys_nodup <- keys[!duplicated(keys) & keys != "NULL"]
keys_nodup
# create data frame of keys and matching taxon_name
gbif_codes <- map_df(keys_nodup,~as.data.frame(.x),.id="taxon_name")
names(gbif_codes)[2] <- "speciesKey"
# create vector of keys as input into gbif download
gbif_taxon_keys <- gbif_codes[,2]
# download GBIF data (Darwin Core Archive format)
gbif_download <- occ_download(
pred_in("taxonKey", gbif_taxon_keys),
pred_in("basisOfRecord", c("PRESERVED_SPECIMEN",
"HUMAN_OBSERVATION","FOSSIL_SPECIMEN","OBSERVATION",
"UNKNOWN","MACHINE_OBSERVATION","MATERIAL_SAMPLE",
"LITERATURE")),
#pred("hasCoordinate", TRUE),
#pred("hasGeospatialIssue", FALSE),
format = "DWCA", #"SIMPLE_CSV"
user=user,pwd=pwd,
email=email)
# load gbif data just downloaded
# create new folder for data and set as working directory
dir.create(file.path(getwd(),"gbif_read_in"))
setwd(file.path(getwd(),"gbif_read_in"))
# download and unzip before reading in
gbif_download # !!! PASTE "Download key" as first argument in next two lines !!!
occ_download_get(key="0327160-200613084148143", overwrite=TRUE)
unzip("0261226-200613084148143.zip")
# read in data
gbif_raw <- fread("occurrence.txt",quote="")
unzip("0327160-200613084148143.zip")
# read in data
gbif_raw <- fread("occurrence.txt",quote="")
nrow(gbif_raw) #2399719
write.csv(gbif_raw, paste0(my_dir,"\\gbif_raw.csv"))
################################################################################
# C) Integrated Digitized Biocollections (iDigBio) download
################################################################################
# download iDigBio data for target taxa
# we have to go taxon by taxon; function can only return 100,000
#   records at once and Quercus has more than that so can't download by genera
idigbio_raw <- data.frame()
for(i in 1:length(taxon_names)){
output_new <- idig_search_records(rq=list(scientificname=taxon_names[[i]]),
fields="all")
idigbio_raw <- rbind(idigbio_raw,output_new)
print(paste(round(i/length(taxon_names)*100,digits=1),"% complete",sep=""))
}
nrow(idigbio_raw) #2114
# remove rows that are lists
idigbio_raw <- idigbio_raw %>% select(everything(),-commonnames,-flags,
-mediarecords,-recordids)
# write file
write.csv(idigbio_raw, paste0(my_dir,"\\idigbio_raw.csv"))
# download BIEN occurrence data for target genera
bien_raw <- BIEN_occurrence_species(species_names,all.taxonomy=T,native.status=T,
natives.only=F,observation.type=T,collection.info=T,political.boundaries=T,
cultivated=T)
nrow(bien_raw) #2326
# write file
write.csv(bien_raw, paste0("bien_raw.csv"))
# searches for data frame columns with only NAs and removes them
remove.empty.col <- function(df){
remove <- vector(mode = "character")
for(i in 1:ncol(df)){
if(sum(is.na(df[,i])) == nrow(df)){
remove <- c(remove,names(df)[i])
print(names(df)[i])
}
}
if(length(remove)>0){
df <-  df[,-which(names(df) %in% remove)]
}
return(df)
}
# calculates percent of each data frame column that is not NA
percent.filled <- function(df){
for(i in 1:ncol(df)){
print(paste(names(df)[i],": ",
round((nrow(df)-sum(is.na(df[,i])))/nrow(df),3)*100,"%",sep=""))
}
}
################################################################################
# C) Integrated Digitized Biocollections (iDigBio) download
################################################################################
# download iDigBio data for target taxa
# we have to go taxon by taxon; function can only return 100,000
#   records at once and Quercus has more than that so can't download by genera
idigbio_raw <- data.frame()
for(i in 1:length(taxon_names)){
output_new <- idig_search_records(rq=list(scientificname=taxon_names[[i]]),
fields="all")
idigbio_raw <- rbind(idigbio_raw,output_new)
print(paste(round(i/length(taxon_names)*100,digits=1),"% complete",sep=""))
}
nrow(idigbio_raw) #4152
# remove rows that are lists
idigbio_raw <- idigbio_raw %>% select(everything(),-commonnames,-flags,
-mediarecords,-recordids)
# write file
write.csv(idigbio_raw, paste0(my_dir,"\\idigbio_raw.csv"))
